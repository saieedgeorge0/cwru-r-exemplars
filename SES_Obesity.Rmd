---
title: "SES and Obesity Status: Using Chi-Squared"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
####George Saieed
####4/22/2020

## Downloading R and R Studio

This lesson assumes you have current versions of the following installed on your computer:

[The R software itself](https://cran.r-project.org/mirrors.html), and [RStudio Desktop](https://rstudio.com/products/rstudio/download/#download)

##Downloading the data
Start by going [here](https://www.cdc.gov/brfss/annual_data/annual_2018.html), scroll down, and select "2018 BRFSS Data (SAS Transport Format)." This will download a ZIP file to your laptop - double click it to unzip it, and move the resulting .XPT file **into the same folder as this Rmd file**. This is the raw (unprocessed) data we will be using for this data analysis example - we'll talk about it in more detail later.

##Set Your Working Directory
Once you've ensured that this Rmd file and the data we just downloaded are in the same folder, we can set our working directory. This should be the folder that this Rmd file is saved in. This tells R where in our file system to look when we come to reference and manipulate files later on.

```{r}
#this is the command to change the working directory
setwd("/Users/George/OneDrive/Projects/SES-Obesity-Status")

#IF YOU USE WINDOWS
#setwd("C:/Users/George/OneDrive/Projects/SES-Obesity-Status")
```

##The Data We'll Be Using + Choice of Test
This dataset is the 2018 Behavioral Risk Factor Surveillance System from the CDC. The data comes from a series of "national health-related telephone surveys that collect state data about U.S. residents regarding their health-related risk behaviors, chronic health conditions, and use of preventive services. Established in 1984 with 15 states, BRFSS now collects data in all 50 states as well as the District of Columbia and three U.S. territories. BRFSS completes more than 400,000 adult interviews each year, making it the largest continuously conducted health survey system in the world." The survey collects a huge amount of data from individuals regarding their health - if you're interested in looking at everything the survey asks about, you can view the codebook [here](https://www.cdc.gov/brfss/annual_data/2018/pdf/codebook18_llcp-v2-508.pdf). 

In our case, we're interested in two specific variables: income of the responder and their "Obesity Status," as classified by BMI. We want to determine if there is a significant relationship between these two variables; in essence, we want to see if BMI is independent from income level **in the state of Ohio**. Because both of these variables are nominal variables (they're both categorical), we're going to use the Chi-Squared Test of Independence (more on this later). **Before we begin, I want to stress that the purpose of this exercise is to demonstrate how to use R to run this test on some data, and that it is not intended to be an example of a "good" study - that is, I will not be talking in depth about survey design/weighting, biases, etc.**

##Looking at our Data and Determining What Exactly We Need
We first need to figure out what data from this file/dataset we want exactly. If we go into the codebook for the BRFSS dataset (see link above), we can find BMI values collected under the label of "Computed Body Mass Index." **Note the SAS variable name for this is \_BMI5CAT.** We'll need this later. There are **four categories,** and each range of BMIs has a classification.

| Coding | BMI | Classification |
| ---- | ---- | ---- |
| 1 | < 18.50 | Underweight |
| 2 | 18.50 - 25.00 | Normal Weight |
| 3 | 25.00 - 30.00 | Overweight |
| 4 | 30.00 - 99.99 | Obese |

We also need to find data on income level, so if we do some more digging into the codebook, we'll find what we want under the label "Income Level.\" **Note the SAS variable name for this is \_INCOME2.** We'll need this later. There are **11 categories** here (note the don't know/refused/not asked categories):

| Coding | Income Level |
| ---- | ---- |
| 1 | Less than $10,000 |
| 2 | \$10,000 - \$15,000 |
| 3 | \$15,000 - \$20,000 |
| 4 | \$20,000 - \$25,000 |
| 5 | \$25,000 - \$35,000 |
| 6 | \$35,000 - \$50,000 |
| 7 | \$50,000 - \$75,000 |
| 8 | \$75,000+ |
| 77 | Don't know / Not sure|
| 99 | Refused |

Finally, we want to know which state (by FIPS code) each respondent lives in so that we can perform our analysis on Ohio residents. We'll find what we want under the label "State." **Note the SAS variable name for this is \_STATE.**

##Putting our Data into a CSV
####You do NOT need to understand this section, but I have provided it in case you have a more rigorous statistical/coding background and are curious. If not, download brfss_untidy.csv from Github and skip to the next section.
We're going to start by cleaning the dataset that we've downloaded. This part is relatively complicated and you do not need to fully understand what's going on if you're starting out with a CSV file full of data (which most of you probably will when you do your own projects), but because we are not, we need to first take our data and put it into a CSV so that it's easier to work with. The data we have now is a .XPT file, which is output generated by SAS (a statistical analysis system developed by SAS Institute for data management and analysis). In order to do this, we first need to install and load some packages that'll help us out. If you want to learn more about them, just do a quick Google search of "R package *packagename*."

Install Hmisc, Survey, dplyr, readxl, and Tidyverse by copying and pasting **install.packages(c("Hmisc", "survey", "tidyverse", "dplyr", "readxl"))** into your console. If you put all five into a vector using c(), we can do this in one command. *Hmisc* is a package that allows for character string manipulation, recoding of variables, etc. *Survey* is a package that'll allow us to more easily analyze survey data. *readxl* lets us read in excel files. *Tidyverse* and *dplyr* are packages that will also help us out with data science.

Next, we'll load our packages:

```{r, warning=FALSE, message=FALSE}
# Load Hmisc, survey, dplyr, readxl, and Tidyverse
# We can't use the same trick for loading multiple packages at once, unfortunately
# We will need all of these later

library("Hmisc")
library("survey")
library("tidyverse")
library("dplyr")
library("readxl")
```

We now need to pull the data we need and put it into a CSV file.

```{r}
# This is outside the scope of this tutorial, but we run this first command to set options for our survey package - our current survey design object contains a stratum with only one sampled primary sampling unit (PSU). As a result, we have to center any single-PSU strata around a sample grand mean rather than the stratum mean. If this makes no sense to you, don't worry about it.
options(survey.lonely.psu = "adjust")

# Because this is SAS data, we need to use a special function to import it into R as a dataframe. Be careful - when I first downloaded this, there was an extra space at the end of the file name - make sure you delete it first.
brfssDataFrame <- sasxport.get('LLCP2018.XPT') #this will work if your data is in the same folder as your Rmd

# We need to specify a complex survey design.
# id specifies cluster ids - we have no clusters, so we can use ~0 or ~1.
# strata and weights specifies strata/sampling weights. These are provided in our data already (variable names are ststr and llcpwt)
# Finally, data points at the dataframe we just made, brfssDataFrame
brfssDesign <- svydesign(id = ~1, strata = ~x.ststr, weights = ~x.llcpwt, data = brfssDataFrame)

# Now we create a dataframe with only what we want/need.
# data.frame(svytable()) lets us first create a survey table from the data, then put it into a data frame
# Remember the variables we selected frome above? We said we need _BMI5CAT, _INCOME2, and _STATE.
# we take these three variables and include them from our survey design created above, brfssDesign
# Like Ellen mentioned in the last example, %>% is like a "then" operator. We're creating our data frame THEN
# using write_csv, which will write our data frame to a file called brfss_untidy.csv.
obeseDataFrame <- data.frame(svytable(~x.bmi5cat+income2+x.state, round=TRUE, design=brfssDesign)) %>% write_csv('brfss_untidy.csv')

#view the first few lines of our dataframe
head(obeseDataFrame)
```

## Tidying up our data
As you will see in a moment, 90% of the hard work for this example comes from actually cleaning our data. Running the statistical test is a breeze in comparison - despite the difficulty of the former, it's important to know to clean and recode data because you will almost never receive data organized exactly the way you want.

If you skipped the last section, make sure you download the 'brfss_untidy.csv' from the Github repository where this is being hosted. When we look at this file, we see that our data is arranged in a table that looks like this:

| x.bmicat | income2 | x.state | Freq |
| ---- | ---- | ---- | ---- |
| 1 | 1 | 1 | 14041 |
| 2 | 1 | 1 | 50283 |
| 3 | 1 | 1 | 42382 |
| 4 | 1 | 1 | 83175 |
| 1 | 2 | 1 | 4781 |
| ... | ... | ... | ... |

We want to make this easier for us to work with and understand. As a result, we're going to **recode** the data so that it makes more sense to us at a glance. For our BMI Data, we'll replace 1-4 with the appropriate categorization (underweight, normal weight, overweight, obese), and set any BLANK data as "missing". We'll also condense our income levels; we can make 1-4 a single category of under \$25,000, 5-7 another category of \$25,000 - \$75,000, 8 a category of \$75,000+, and 77 and 99 we will boths assign as "missing." Hopefully this makes sense - if not, scroll up and take another look at the tables above. Finally, we have another issue - our "state" column is not text, but rather state FIPS codes, which are federal numerical identifiers for states.

If you're starting by just downloading the "brfss_untidy.csv":
```{r}
# We will read the data in our CSV into a dataframe.
obeseDataFrame <- read_csv('brfss_untidy.csv', col_types='fffi')
head(obeseDataFrame)
```

We want to be able to convert our FIPS codes to actual state names. We can download FIPS codes from [here](https://www.census.gov/geographies/reference-files/2018/demo/popest/2018-fips.html) as an XLSX file. Put it in the same folder as everything else. We want to read this in as a dataframe:

```{r}
fipsDataFrame <- read_excel('statefips.xlsx', skip = 6, col_names = c('fips', 'state'), col_types=c('skip', 'skip', 'text', 'text')) %>% # we're importing the xlsx, skipping the first 6 rows (which only have labels/nonsense), and skipping the first two columns as we don't need those either. we're naming the two columns we do need fips and state, and THEN:
  mutate(fips=as.character(as.integer(fips))) # a bit confusing but basically we're mutating the fips variable so we can convert our fips codes first into integers and then those integers into characters.
head(fipsDataFrame)
```

We'll now recode our data. This is a long command - I will try to explain what is happening on each line using comments:

```{r}
cleanedObeseDF <- obeseDataFrame %>% # we're taking our obeseDataFrame and THEN (%>%)
  mutate(bmi=fct_recode(x.bmi5cat, # we're going to rename our bmi variable just "bmi," recoding the original "x.bmi5cat".
                        underweight = '1', #set 1s to "underweight"
                        normal = '2', #set 2s to "normal weight"
                        overweight = '3', #set 3s to "overweight"
                        obese = '4'), #set 4s to "obese"
         income=fct_recode(income2,
                           less_than_25k='1', # set 1-4 to "less_than_25k"
                           less_than_25k='2',
                           less_than_25k='3',
                           less_than_25k='4',
                           btw_25k_and_75k='5', # set 5-7 to "btw_25k_and_75k"
                           btw_25k_and_75k='6',
                           btw_25k_and_75k='7',
                           greater_than_75k='8', # set 8 to "greater_than_75k"
                           missing='77', # set 77 and 99 to "missing"
                           missing='99'),
         fips=as.character(x.state), # convert each x.state fips code to a character, rather than integer, rename to fips
         count=Freq) %>% #rename Freq variable to count, and THEN
  filter(fips != '66', fips != '72') %>% # we're filtering out FIPS codes 66/72, which are Guam and PR. Our XLSX file with FIPS code did not include these, so we won't either, and THEN
  left_join(fipsDataFrame, by='fips') %>% # a left join will merge two data frames: all rows from the first table and any matching rows from the second table, by a specific variable (in this case, we'll merge fipsDataFrame to cleanedObeseDF, merging rows if they have the same FIPS code), and THEN
  group_by(state, bmi, income) %>% 
  summarize(count=sum(Freq)) # these last two lines group our data so it's more organized: we want to group first by state, then by bmi, then by income, and then sum up any duplicates. So, for example, we have multiple row for Alabama with a count for people who are underweight and who make under 25,000 dollars - we want to sum this up so that we only have row per state/bmi/income set.

cleanedObeseDF %>% write_csv('brfss_tidy.csv') # put this dataframe into a CSV in case we need it later
head(cleanedObeseDF)
```

## Isolating the Exact Data We Want
That was a lot, I know. Almost there, though - stick with it! Next we want to 1) select only rows for the state of Ohio, and we'll want to exclude rows where data is missing.

```{r}
ohioDF <- cleanedObeseDF %>% filter(state == 'Ohio') # select only rows where the state is Ohio
ohioDF <- ohioDF %>% filter(income != 'missing') # select all rows except where income equals missing
print(ohioDF)
```

That's it! We now have all the data we need to run our chi-squared test in our *finalDF* dataframe.

## What is the Chi-Squared Independence Test?
For any hypothesis test, we need a null hypothesis and an alternative hypothesis:

$H_0$:  the two variables are independent

$H_A$: the two variables are *not independent* (ie: they are dependent) 

To test the hypothesis we will perform a chi-squared ($\chi^2$) independence test for the data. This will give us a p-value that we can then interpret. I will not go into more detail than this - the first week of this course has a video on chi-squared and how to properly interpret it.

#Performing the Actual Statistical Analysis
First, we want to put our data into a 3x4 table. Then we'll run our chi-squared test. **Please note**: this data was weighted in the first part of this example (which you may have skipped), as it is survey data. The function we use below to actually run the chi-squared test is a generic function in R and does not account for these weights. If you understand what I'm talking about, feel free to run another test accounting for it yourself using the function [svychisq](http://r-survey.r-forge.r-project.org/survey/html/svychisq.html).

```{r}
obeseTable = xtabs(count ~ bmi + income, ohioDF) # creates a contingency table with BMI and Income as row/column, using count as the value for each pairing.
obeseTable = obeseTable[, -4] # remove the "missing" column (which is the 4th column) which persists for some reason
print(obeseTable)
chisq.test(obeseTable) # run chi-squared independence test on our data!
```

We get a p-value of 2.2e-16, which is considerably lower than the 0.05 significance level, so we reject the null hypothesis that BMI is independent of income level in the state of Ohio.